{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "growing-black",
   "metadata": {
    "id": "growing-black"
   },
   "source": [
    "# ML Methods: Online Learning, Semi-Supervised Learning, Few-Shot Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272f7c2e",
   "metadata": {
    "id": "accomplished-macedonia"
   },
   "source": [
    "# Table of Contents\n",
    "* [Introduction](#introduction)\n",
    "* [Online Learning](#online-learning)\n",
    "    * [Continual Learning](##continual-learning)\n",
    "* [Semi-Supervised Learning](#semi-suipervised-learning)\n",
    "* [Few-Shot Learning](#few-shot-learning)\n",
    "    * [Meta-Learning](##meta-learning)\n",
    "        * [Model-Agnostic Meta-Learning](###model-agnostic-meta-learning)\n",
    "* [Other useful links](#Finally...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gBGkgt81cn2i",
   "metadata": {
    "id": "gBGkgt81cn2i"
   },
   "source": [
    "# Introduction\n",
    "In this notebook, we take a brief look at different Machine Learning methods such as online learning, semi-supervised learning, and few-shot learning. The ultimate goal of this content is to provide a shallow knowledge of the aforementioned topics and helpful resources for further studies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sudden-theology",
   "metadata": {
    "id": "sudden-theology"
   },
   "source": [
    "# Online Learning\n",
    "\n",
    "Online machine learning is a machine learning method in which data becomes available in sequential order and is used to update the best predictor for future data at each step, as opposed to batch learning techniques that generate the best predictor by learning on the entire training data set at once. [Here](https://www.youtube.com/watch?v=O3gd6elZOlA) is a youtube tutorial that might help with getting more familiar with this group of ML methods.\n",
    "\n",
    "\n",
    "## Continual learning\n",
    "* Continual learning means constantly improving the learned model by processing continuous streams of information. Continual learning capabilities are essential for software systems and autonomous agents interacting in an ever changing real world.\n",
    "\n",
    "* Many refer to continual learning and online learning as synonyms, but people have different opinions on this. Some believe that continual learning is a subset of online learning that deals with [catastrophic forgetting](https://en.wikipedia.org/wiki/Catastrophic_interference), whereas standard “online learning” is more naive and incurs forgetting.\n",
    "\n",
    "* Ideally, what you want is a model that can learn from new examples in something close to real time. Not only predict in real time, but learn in real time, too.\n",
    "\n",
    "* [This article](https://medium.com/value-stream-design/online-machine-learning-515556ff72c5) provides great information and examples in this regard."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "utility-shark",
   "metadata": {
    "id": "utility-shark"
   },
   "source": [
    "<img src=\"https://www.analyticsvidhya.com/wp-content/uploads/2015/01/schematics.png\" width=\"650\" height=\"650\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authorized-scotland",
   "metadata": {
    "id": "authorized-scotland"
   },
   "source": [
    "# Semi-Suipervised Learning\n",
    "Semi-supervised learning is an approach to machine learning that combines a small amount of labeled data with many unlabeled data during training. Semi-supervised learning falls between unsupervised learning (with no labeled training data) and supervised learning (with only labeled training data). More specifically, it is a particular instance of weak supervision."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colonial-ticket",
   "metadata": {
    "id": "colonial-ticket"
   },
   "source": [
    "* Pseudo Labeling: Assume that only a small portion of our training data is labeled. To get the most out of our training data, we should assign correct labels to unlabeled data. We train a supervised model with our labeled data in pseudo labeling and utilize its predictions for setting labels for the unlabeled data. [This youtube tutorial](https://www.youtube.com/watch?v=b-yhKUINb7o) might help with a better understanding."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "younger-netherlands",
   "metadata": {
    "id": "younger-netherlands"
   },
   "source": [
    "<img src=\"https://www.researchgate.net/publication/345432485/figure/fig1/AS:955199128608771@1604748627675/Pseudo-Labeling-Learning-Architecture.png\" width=\"650\" height=\"650\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "potential-chick",
   "metadata": {
    "id": "potential-chick"
   },
   "source": [
    "# Few-Shot Learning\n",
    "\n",
    "Few-shot learning is the problem of making predictions based on a limited number of samples. Few-shot learning is different from standard supervised learning. The general model should adapt efficiently with a small number of training data for a given task. In most cases, we need to prepare a model capable of this fast adaptation. \n",
    "\n",
    "\n",
    "*   **Support Set**: Support set is meta learning’s jargon. The small set of labeled data (e.g., images) is called a support set. Note the differences between the training set and the support set. The training set is extensive. Every class in the training set has many samples. The training set is big enough for the learning process of a deep neural network. In contrast, the support set is small. Every class has at most a few samples. If every class has only one sample in the training set, it is impossible to train a deep neural network. Thus, we have support sets instead of training sets in few-shot learning.\n",
    "\n",
    "*   **Query Set**: Is the set of unlabled data that the model should predict after trained on the support set of this particular task. The definition is close to the test set in regular machine learning methods.\n",
    "\n",
    "*   **One-Shot Learning**: As the title explains, the task only contains one training example to learn.\n",
    "\n",
    "*   **FSL in Classification**: When talking about FSL in classification, we usually mean N-way-K-Shot-classification. N stands for the number of classes, and K for the number of samples from each class to train on.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cd116482",
   "metadata": {},
   "source": [
    "<img src=\"https://i0.wp.com/neptune.ai/wp-content/uploads/few-shot-classification-problem.jpeg?resize=684%2C483&ssl=1\" width=\"600\" height=\"600\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expected-waterproof",
   "metadata": {
    "id": "expected-waterproof"
   },
   "source": [
    "## Meta-Learning\n",
    "Few-shot learning is a kind of meta-learning. Meta-learning is different from traditional supervised learning. Conventional supervised learning asks the model to recognize the training data and then generalize to unseen test data. Differently, meta learning’s goal is to learn. In other words, in meta-learning, the goal is to find a set of parameters that can adapt as quickly as possible for a new given task. We discuss one of the essential meta-learning platforms in the following section.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manufactured-novel",
   "metadata": {
    "id": "manufactured-novel"
   },
   "source": [
    "### Model-Agnostic Meta-Learning\n",
    "MAML, or Model-Agnostic Meta-Learning, is a model and task-agnostic algorithm for meta-learning that trains a model’s parameters such that a small number of gradient updates will lead to fast learning on a new task."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "yxtWWHKsa4k8",
   "metadata": {
    "id": "yxtWWHKsa4k8"
   },
   "source": [
    "<img src=\"http://bair.berkeley.edu/static/blog/maml/maml.png\" width=\"400\" height=\"400\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "partial-feeling",
   "metadata": {
    "id": "partial-feeling"
   },
   "source": [
    "In this algorithm, which can be used in federated learning, each agent adapts the general set of parameters (known as theta) independently for its task using the support set. Subsequently, the gradient of the loss function using the query set (which is also labeled because it is in the learning section) is computed and transferred to the root. Then, the root updates the general theta concerning all the received gradients of different agents (tasks)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "treated-stick",
   "metadata": {
    "id": "treated-stick"
   },
   "source": [
    "[Here](https://www.youtube.com/watch?v=wT45v8sIMDM&t=1286s) is a youtube tutorial that could help with a better understanding of MAML. If you are more into text sources, [here](https://www.instadeep.com/research/blog/model-agnostic-meta-learning-made-simple/) is a good one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "palestinian-trigger",
   "metadata": {
    "id": "palestinian-trigger"
   },
   "source": [
    "[Here](https://arxiv.org/abs/1703.03400) is the link to the original paper proposing MAML."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflected-amino",
   "metadata": {
    "id": "reflected-amino"
   },
   "source": [
    "MAML is easily implemented on the [learn2learn](https://github.com/learnables/learn2learn) GitHub repository. A simple experiment could be running [this python file](https://github.com/learnables/learn2learn/blob/master/examples/vision/meta_mnist.py), which executes MAML for MNIST image classification tasks. You can manage input parameters by providing proper arguments to this python code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dense-nudist",
   "metadata": {
    "id": "dense-nudist"
   },
   "source": [
    "## Finally...\n",
    "Check these links out for more information on topics covered in this notebook.\n",
    "\n",
    "* [More about few-shot learning and meta-learning](https://www.borealisai.com/en/blog/tutorial-3-few-shot-learning-and-meta-learning-ii/)\n",
    "\n",
    "* [A full explanation of Meta-Learning: Learning to Learn Fast](https://lilianweng.github.io/lil-log/2018/11/30/meta-learning.html)\n",
    "\n",
    "* [Wikipedia for semi-supervised learning](https://en.wikipedia.org/wiki/Semi-supervised_learning)\n",
    "\n",
    "* [Learning with not enough data, Semi-supervised learning](https://lilianweng.github.io/lil-log/2021/12/05/semi-supervised-learning.html)\n",
    "\n",
    "* [A youtube tutorial for iMAML](https://www.youtube.com/watch?v=u5BkO8XMS2I&t=19s)\n",
    "\n",
    "* [Introduction to Online Machine Learning Algorithms](https://www.youtube.com/watch?v=O3gd6elZOlA)\n",
    "\n",
    "* [Online machine learning with codes](https://medium.com/value-stream-design/online-machine-learning-515556ff72c5)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "ML-methods.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
